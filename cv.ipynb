{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output, display\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "french_stopwords = list(fr_stop)\n",
    "from scipy import stats\n",
    "import math\n",
    "import string\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/home/serge/proj/streamer/\")\n",
    "from fun import *\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildGraphFrom2DF(FinalInf,graphdf):\n",
    "\n",
    "    \"\"\"\n",
    "    Input : un dataframe des nodes\n",
    "    Input : un dataframe des links\n",
    "    Output : un objet graph igraph\n",
    "    \"\"\"\n",
    "    \n",
    "    g = ig.Graph(directed=False)\n",
    "    nodesids = FinalInf.GRAPHID.values\n",
    "    g.add_vertices(nodesids)\n",
    "\n",
    "    g.vs[\"AUTHORDESCRIPTION\"] = FinalInf.AUTHORDESCRIPTION.tolist()\n",
    "    g.vs[\"AUTHORFNAME\"] = FinalInf.AUTHORFNAME.tolist()\n",
    "    g.vs[\"AUTHORID\"] = FinalInf.AUTHORID.tolist()\n",
    "    g.vs[\"AUTHORNAME\"] = FinalInf.AUTHORNAME.tolist()\n",
    "    g.vs[\"AUTHORFOLLOWERS\"] = FinalInf.AUTHORFOLLOWERS.tolist()\n",
    "\n",
    "    edgeslist = graphdf[[\"GRAPHIDA\",\"GRAPHIDB\"]].values.tolist()\n",
    "    g.add_edges(edgeslist)\n",
    "    g.es[\"weight\"] = graphdf.f.tolist()\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "def DeleteSomeNodes(g,AttributeName,ThresholdFollowersInf,ThresholdFollowersSup):\n",
    "\n",
    "    \"\"\"\n",
    "    Input : un objet igraph graph\n",
    "    Input : borne inferieur et superieur\n",
    "    Input : Attribute Name\n",
    "    Output : un objet igraph graph\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    to_delete_ids = [node for node in g.vs if node[AttributeName]<ThresholdFollowersInf]\n",
    "    g.delete_vertices(to_delete_ids)\n",
    "\n",
    "    to_delete_ids = [node for node in g.vs if node[AttributeName]>ThresholdFollowersSup]\n",
    "    g.delete_vertices(to_delete_ids)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphdf = pd.read_csv(\"graph1581156942.csv\")\n",
    "graphdf.sort_values(by=\"f\",ascending=False,inplace=True)\n",
    "nodesids = np.unique(np.hstack((graphdf.a.values,graphdf.b.values)))\n",
    "\n",
    "FinalInf = PickleLoad(\"FinalInf.pkl\")\n",
    "FinalInf = FinalInf[FinalInf.AUTHORID.isin(nodesids)]\n",
    "FinalInf = FinalInf.reset_index(drop=True).reset_index()\n",
    "FinalInf.rename(columns = {\"index\":\"GRAPHID\"},inplace=True)\n",
    "\n",
    "graphdf = graphdf.merge(FinalInf[[\"GRAPHID\",\"AUTHORID\"]],how=\"left\",left_on=\"a\",right_on=\"AUTHORID\").rename(columns={\"GRAPHID\":\"GRAPHIDA\"})\n",
    "graphdf = graphdf.merge(FinalInf[[\"GRAPHID\",\"AUTHORID\"]],how=\"left\",left_on=\"b\",right_on=\"AUTHORID\").rename(columns={\"GRAPHID\":\"GRAPHIDB\"})\n",
    "graphdf.drop(columns=[\"AUTHORID_x\",\"AUTHORID_y\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThresholdFollowersInf = 20000\n",
    "ThresholdFollowersSup = 80000\n",
    "AttributeName = \"AUTHORFOLLOWERS\"\n",
    "g = BuildGraphFrom2DF(FinalInf,graphdf)\n",
    "g = DeleteSomeNodes(g,AttributeName,ThresholdFollowersInf,ThresholdFollowersSup)\n",
    "todelete = [node for node in g.vs if node.degree()==0]\n",
    "g.delete_vertices(todelete)\n",
    "todelete = [edge for edge in g.es if edge[\"weight\"]>4]\n",
    "g.delete_edges(todelete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = g.community_multilevel(weights=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupérer les graph csv pour la vue globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractNextBorne(SelectedID,x,verbose=False):\n",
    "\n",
    "    try:\n",
    "        InfValue = x[SelectedID][1]\n",
    "        if verbose:\n",
    "            print(InfValue)\n",
    "        \n",
    "        ChampDesPossibles = np.array([item[0] for item in x[SelectedID + 1 :len(x)]])\n",
    "        if verbose:\n",
    "            print(ChampDesPossibles)\n",
    "        \n",
    "        Distance = np.abs(InfValue - ChampDesPossibles)\n",
    "        if verbose:\n",
    "            print(Distance)\n",
    "        \n",
    "        idres = np.argmin(Distance) + SelectedID + 1 \n",
    "        if verbose:\n",
    "            print(idres)\n",
    "        \n",
    "        res = x[idres]\n",
    "        if verbose:\n",
    "            print(res)\n",
    "        \n",
    "    except:\n",
    "        idres = None\n",
    "        res = None\n",
    "    \n",
    "    return idres,res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractAllBornes(x):\n",
    "\n",
    "    \"\"\"\n",
    "    Input : liste de tuples représentant les bornes\n",
    "    Output : liste de tuples représentant les bornes les plus revelantes\n",
    "    \"\"\"\n",
    "    \n",
    "    x.sort(key = lambda a : a[1], reverse = False)\n",
    "    SelectedID = 0\n",
    "    borne = x[SelectedID]\n",
    "    L = [borne]\n",
    "\n",
    "    while True:\n",
    "        idres,res = ExtractNextBorne(SelectedID,x)\n",
    "        if idres is not None:\n",
    "            SelectedID = idres\n",
    "            L.append(res)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [(0,10),\n",
    " (2,12),\n",
    " (4,14),\n",
    " (6,16),\n",
    " (8,18),\n",
    " (4,11),\n",
    " (12,22),\n",
    " (14,24),\n",
    " (16,26),\n",
    " (180,280),\n",
    " (200,300),\n",
    " (220,320)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition de la liste des bornes\n",
    "BornesList = [(v[\"start\"],v[\"tm\"]) for k,v in gdic.items()]\n",
    "\n",
    "# Extraction des bonnes bornes\n",
    "MyBornes = ExtractAllBornes(x)\n",
    "\n",
    "# Extraction de la TimeMarkList\n",
    "TimeMarkList = [item[1] for item in MyBornes]\n",
    "\n",
    "# Création du global links dataframe\n",
    "L = []\n",
    "ListOfSelectedDataFrames = [item[\"linksdf\"] for item in gdic.keys() if item in TimeMarkList]\n",
    "GlobalLinksDF = pd.concat(ListOfSelectedDataFrames,axis=0,sort=True)\n",
    "GlobalStatsDF = GlobalLinksDF.groupby([\"a\",\"b\"])[\"f\"].sum().reset_index()\n",
    "\n",
    "# Création de FinalInf, GlobalStatsDF\n",
    "# ...\n",
    "\n",
    "# Parameters du filtre du graph\n",
    "g = BuildGraphFrom2DF(FinalInf,graphdf)\n",
    "\n",
    "# Filtrage du graph g\n",
    "# ...\n",
    "\n",
    "# Clustering du graph\n",
    "clustering = g.community_multilevel(weights=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bleckwenn**, AntiFraud Company\n",
    "\n",
    "* Goal : improve global graph algorithms performance\n",
    " * Developpement : subgraph extraction model\n",
    " * Example : get \"relevant\" ego graph of a node, bypassing hubs and dead \"links\" and outliers \"links\"\n",
    "\n",
    "\n",
    "* Goal : improve fraudulent operations detection model\n",
    " * Developpement : build bunch of features that would characterize a transaction\n",
    " * Example : age of an account, past operations, countries involved, banks involved, validation\n",
    "\n",
    "\n",
    "* Goal : detect events by listenning meta data communications within a group of people \n",
    " * Developpement : events extraction model via twitter data\n",
    " * Example : giving the activity on twitter this monday, something unusual happens within this community\n",
    " * Justification : crime is an activity played in a group. One fraudulent transaction implies a community of criminals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suneris**, Military Intelligence\n",
    "\n",
    "* Goal : extract spatiotemporal habits\n",
    " * Developpement : Hierarchical spatial areas clustering\n",
    " * Developpement : Hierarchical temporal patterns cycles detection\n",
    " * Example : Where and when can I find him?\n",
    "\n",
    "\n",
    "* Goal : Guessing phone numbers\n",
    " * Developpement : Matching habits model\n",
    " * Example : If he got an other number, what it could be?\n",
    "\n",
    "\n",
    "* Goal : track identified spatiotemporal habits in order to raise alert when something unusual happens\n",
    " * Developpement : Temporal patterns breakouts detection model\n",
    " * Exemple : he used to go there with a high confidence, but today no, something might happen\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bouygues**,  Telecom\n",
    "\n",
    "* Goal : detect types of failures of the newtork by analysing sequence of the hotline suggested actions\n",
    " * Developpement : extract frequent subsequences patterns\n",
    " * Developpement : model that predict type of failures from patterns\n",
    " * Developpement : application that run the predictive model over a sliding window and may raise alert in case of dominating type of failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Orange**, Telecom\n",
    " * Goal : enrich a model that explains the customer dissatisfaction\n",
    "  * Developpement : features extraction based on sequence of events that users trigger via their remote control\n",
    "  * Example : the subsequence [*TurnOn - TurnOff - TurnOn*] in short period of time is highly correlated to dissatisfaction, so we want to incorporate this feature into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
