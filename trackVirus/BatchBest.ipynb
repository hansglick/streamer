{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output, display\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadJsonFile(filename): \n",
    "    with open(filename, 'r') as f:\n",
    "        DicConfig = json.load(f)\n",
    "    return DicConfig\n",
    "\n",
    "\n",
    "def GlobalDicDeplier(OneDic):\n",
    "    for k,v in OneDic.items():\n",
    "        exec('globals()[k] = v')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Config variables\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement du fichier config.json\")\n",
    "print(\"\")\n",
    "DicConfig = LoadJsonFile(os.path.join(os.getcwd(),\"config.json\"))\n",
    "GlobalDicDeplier(DicConfig)\n",
    "sys.path.append(Root)\n",
    "from fun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "print(\"Load data\")\n",
    "print(\"\")\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"RefFam.pkl\")\n",
    "RefFam = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"RefRT.pkl\")\n",
    "RefRT = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"RefInf.pkl\")\n",
    "RefInf = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"tmdic.pkl\")\n",
    "tmdic = LoadPickleOrInit(path,typeobj=\"dic\")\n",
    "\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"FinalFam.pkl\")\n",
    "FinalFam = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"FinalRT.pkl\")\n",
    "FinalRT = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"FinalInf.pkl\")\n",
    "FinalInf = LoadPickleOrInit(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date du du potentiel next Time Mark :  2020-02-08 13:55:41\n",
      "Date 1er retweet :  2020-02-08 13:35:41\n",
      "Date Dernier retweet :  2020-02-08 13:51:25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Quel est le prochain Time Mark?\")\n",
    "getnexttm(RefRT,tmdic,StepSize,WindowSize,verbose = True)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupérer le next batch de rt et la maj des retweets dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **rtdf** : dataframe de reference des retweets téléchargés. Le fichier est alimenté régulièrement.\n",
    " * **pbest** : proportion de volume de retweets à garder\n",
    " * **tmdic** : dictionnaire dont les clés sont des timemarks, les valeurs peuvent être les bornes inférieurs et supérieurs\n",
    " * **rtdf_period** : dataframe de reference des retweets téléchargés uniquement sur une période\n",
    " * **stepsize** : taille du step de la fenetre glissante en secondes\n",
    " * **windowsize** : taille de la fenêtre glissante en secondes\n",
    " * **tm** : une timemark en secondes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de batch rajoutés :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Analytics commence ...\")\n",
    "\n",
    "\n",
    "tocontinue = True\n",
    "compteur = 0\n",
    "while(tocontinue):\n",
    "    bestrtdf,bestfamdf,bestinfdf,informations,nexttm = getbestrtbashdic(RefRT,\n",
    "                                                                        tmdic,\n",
    "                                                                        StepSize,\n",
    "                                                                        WindowSize,\n",
    "                                                                        TopTweetsProportion,\n",
    "                                                                        RefFam,\n",
    "                                                                        RefInf)\n",
    "    \n",
    "    if nexttm is not None:\n",
    "        compteur = compteur + 1\n",
    "        tmdic[nexttm] = informations\n",
    "        FinalInf = pd.concat((FinalInf,bestinfdf),axis = 0, sort = True)\n",
    "        FinalFam = pd.concat((FinalFam,bestfamdf),axis = 0, sort = True)\n",
    "        FinalRT = pd.concat((FinalRT,bestrtdf),axis = 0, sort = True)\n",
    "\n",
    "        FinalRT = FinalRT.drop_duplicates()\n",
    "        FinalFam = FinalFam.drop_duplicates(subset=[\"AUTHORTWEETID\"])\n",
    "        FinalInf = FinalInf.drop_duplicates(subset=[\"AUTHORID\"])\n",
    "\n",
    "        FinalInf.reset_index(drop=True,inplace=True)\n",
    "        FinalFam.reset_index(drop=True,inplace=True)\n",
    "        FinalRT.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "    else:\n",
    "        tocontinue = False\n",
    "        \n",
    "print(\"Nombre de batch rajoutés : \", compteur)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compteur > 0 :\n",
    "    PickleDump(os.path.join(Root,FolderProject,\"tmdic.pkl\"),tmdic)\n",
    "    PickleDump(os.path.join(Root,FolderProject,\"FinalInf.pkl\"),FinalInf)\n",
    "    PickleDump(os.path.join(Root,FolderProject,\"FinalFam.pkl\"),FinalFam)\n",
    "    PickleDump(os.path.join(Root,FolderProject,\"FinalRT.pkl\"),FinalRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsrt = pd.Series(FinalRT.AUTHORTWEETID.unique()).to_frame(name=\"AUTHORTWEETID\")\n",
    "solution = tweetsrt.merge(FinalFam,on=\"AUTHORTWEETID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 1)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Est-ce que tout est ok?\")\n",
    "print(tweetsrt.shape[0] == solution.shape[0])\n",
    "print(\"taille : \", len(tweetsrt))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = retrievethreshold(tmdic,WindowSize,RefRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valeur du threshold?\")\n",
    "print(threshold)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "if threshold is not None : \n",
    "    RemoveRT,KeepRT = extractkeepremove(RefRT,threshold)\n",
    "    PickleDump(os.path.join(Root,FolderProject,\"RefRT.pkl\"),KeepRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "if threshold is not None:\n",
    "    fil = RefRT.AUTHORTWEETID>=threshold\n",
    "    tempdf = pd.Series(RefRT.AUTHORTWEETID[fil].unique()).to_frame(name=\"AUTHORTWEETID\")\n",
    "    toadd = tempdf.merge(RefFam,on=\"AUTHORTWEETID\")\n",
    "    NewRefFam = pd.concat((toadd,FinalFam),axis=0,sort=True).drop_duplicates(subset=\"AUTHORTWEETID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "if threshold is not None:\n",
    "    PickleDump(os.path.join(Root,FolderProject,\"RefFam.pkl\"),NewRefFam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les 5 dernieres time marks : \")\n",
    "x = list(tmdic.keys())\n",
    "print([pd.to_datetime(item,unit=\"s\") for item in x[::-1][:5]])\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
