{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   * * *   Lancement du Graph.py   * * *   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"   * * *   Lancement du Graph.py   * * *   \")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output, display\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadJsonFile(filename): \n",
    "    with open(filename, 'r') as f:\n",
    "        DicConfig = json.load(f)\n",
    "    return DicConfig\n",
    "\n",
    "\n",
    "def GlobalDicDeplier(OneDic):\n",
    "    for k,v in OneDic.items():\n",
    "        exec('globals()[k] = v')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du fichier config\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement du fichier config\")\n",
    "\n",
    "DicConfig = LoadJsonFile(os.path.join(os.getcwd(),\"config.json\"))\n",
    "GlobalDicDeplier(DicConfig)\n",
    "sys.path.append(Root)\n",
    "from fun import *\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement des données\")\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"FinalFam.pkl\")\n",
    "FinalFam = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"FinalRT.pkl\")\n",
    "FinalRT = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"FinalInf.pkl\")\n",
    "FinalInf = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"gdic.pkl\")\n",
    "gdic = LoadPickleOrInit(path,typeobj=\"dic\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnexttm(rtdf,tmdic,stepsize,graphwin,tfidfwin,verbose = False):\n",
    "    \"\"\"\n",
    "    input : un dictionnaire de timemark\n",
    "    input : le dataframe de retweets reference\n",
    "    input : le stepsize\n",
    "    output : soit un timemark s'il existe, soit un None Type\n",
    "    \"\"\"\n",
    "    \n",
    "    # Le window size\n",
    "    if graphwin>=tfidfwin:\n",
    "        windowsize = graphwin\n",
    "    else:\n",
    "        windowsize = tfidfwin\n",
    "    \n",
    "    # Quel est le timestamp du dernier retweet?\n",
    "    lastretweetts = rtdf.TWEETUNIXEPOCH.max()\n",
    "    firstretweetts = rtdf.TWEETUNIXEPOCH.min()\n",
    "\n",
    "    # Quel est le dernier timemark?\n",
    "    if len(tmdic)>0:\n",
    "        tmlist = list(tmdic.keys())\n",
    "        lasttm = max(tmlist) + stepsize\n",
    "    else:\n",
    "        lasttm = firstretweetts + windowsize\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Date du du potentiel next Time Mark : \",pd.to_datetime(lasttm,unit=\"s\"))\n",
    "        print(\"Date 1er retweet : \",pd.to_datetime(firstretweetts,unit=\"s\"))\n",
    "        print(\"Date Dernier retweet : \",pd.to_datetime(lastretweetts,unit=\"s\"))\n",
    "        print(\"\")\n",
    "    \n",
    "    # ESPACE AVANT\n",
    "    forwardcdt = lastretweetts>lasttm\n",
    "    \n",
    "    if forwardcdt:\n",
    "        return lasttm\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractRawDF(nexttm,FinalRT,GraphWindowSize,GraphTfidfSize):\n",
    "\n",
    "    if nexttm is not None:\n",
    "        bornesup = nexttm\n",
    "        borneinfGraph = nexttm - GraphWindowSize\n",
    "        borneinfTfidf = nexttm - GraphTfidfSize\n",
    "\n",
    "        fil = (FinalRT.TWEETUNIXEPOCH>=borneinfGraph) & (FinalRT.TWEETUNIXEPOCH<bornesup)\n",
    "        rawgraphdf = FinalRT[fil]\n",
    "\n",
    "        fil = (FinalRT.TWEETUNIXEPOCH>=borneinfTfidf) & (FinalRT.TWEETUNIXEPOCH<bornesup)\n",
    "        rawtfidfdf = FinalRT[fil]\n",
    "        \n",
    "\n",
    "\n",
    "    else:\n",
    "        rawgraphdf = None\n",
    "        rawtfidfdf = None\n",
    "\n",
    "    return rawgraphdf,rawtfidfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractGraphDF(rawgraphdf,rawtfidfdf,FinalFam):\n",
    "\n",
    "    if rawgraphdf is not None:\n",
    "        rtstatsdf = rawgraphdf.groupby(\"AUTHORTWEETID\").size().reset_index().rename(columns = {0:\"f\"})\n",
    "        list_of_authors = rawgraphdf.groupby('USERID')['AUTHORID'].apply(list)\n",
    "        LinksDic = GetLinksFromPeriod(list_of_authors)\n",
    "    else:\n",
    "        LinksDic = None\n",
    "        rtstatsdf = None\n",
    "\n",
    "    if rawtfidfdf is not None:\n",
    "        tweetsdf = pd.Series(rawtfidfdf.AUTHORTWEETID.unique()).to_frame(name=\"AUTHORTWEETID\").merge(FinalFam,on=\"AUTHORTWEETID\")\n",
    "        tweetsdf.reset_index(drop=True,inplace=True)\n",
    "    else:\n",
    "        tweetsdf = None\n",
    "\n",
    "    return LinksDic,tweetsdf,rtstatsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunOnePassGraph(FinalRT,gdic,GraphStepSize,GraphWindowSize,GraphTfidfSize,FinalFam):\n",
    "\n",
    "    nexttm = getnexttm(FinalRT,gdic,GraphStepSize,GraphWindowSize,GraphTfidfSize)\n",
    "    rawgraphdf,rawtfidfdf = ExtractRawDF(nexttm,FinalRT,GraphWindowSize,GraphTfidfSize)\n",
    "    LinksDic,tweetsdf,rtstatsdf = ExtractGraphDF(rawgraphdf,rawtfidfdf,FinalFam)\n",
    "\n",
    "    cdta = nexttm is not None\n",
    "    cdtb = LinksDic is not None\n",
    "    cdtc = tweetsdf is not None\n",
    "    cdtd = rtstatsdf is not None\n",
    "\n",
    "    if cdta and cdtb and cdtc and cdtd:\n",
    "        informations = tweetsdf.merge(rtstatsdf,on=\"AUTHORTWEETID\")\n",
    "        gdic[nexttm] = {\"links\":LinksDic,\n",
    "                        \"informations\" : informations[[\"AUTHORTWEETID\",\"AUTHORID\",\"AUTHORTWEETUNIXEPOCH\",\"f\"]],\n",
    "                        \"tmstr\":pd.to_datetime(nexttm,unit=\"s\"),\n",
    "                        \"tm\":nexttm,\n",
    "                        \"GraphStart\":nexttm - GraphWindowSize,\n",
    "                        \"TFIDFStart\":nexttm-GraphTfidfSize}\n",
    "        tocontinue = True\n",
    "    else:\n",
    "        tocontinue = False\n",
    "\n",
    "    return gdic,tocontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la partie Analytics ...\n",
      "1\n",
      "2\n",
      "3\n",
      "Nombre graph rajoutés :  3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Lancement de la partie Analytics ...\")\n",
    "\n",
    "tocontinue = True\n",
    "compteur = 0\n",
    "while tocontinue:\n",
    "    gdic,tocontinue = RunOnePassGraph(FinalRT,gdic,GraphStepSize,GraphWindowSize,GraphTfidfSize,FinalFam)\n",
    "    if tocontinue:\n",
    "        compteur = compteur + 1\n",
    "        print(compteur)\n",
    "\n",
    "print(\"Nombre graph rajoutés : \",compteur)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enregistrement du dictionnaire gdic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Enregistrement du dictionnaire gdic\")\n",
    "\n",
    "PickleDump(os.path.join(Root,FolderProject,\"gdic.pkl\"),gdic)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nettoyage du dataframe FinalRT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Nettoyage du dataframe FinalRT\")\n",
    "\n",
    "threshold = retrievethreshold(gdic,max(GraphWindowSize,GraphTfidfSize),FinalRT)\n",
    "RemoveFinalRT,KeepFinalRT = extractkeepremove(FinalRT,threshold)\n",
    "PickleDump(os.path.join(Root,FolderProject,\"FinalRT.pkl\"),KeepFinalRT)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul des statistiques pour les logs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Calcul des statistiques pour les logs\")\n",
    "\n",
    "if threshold is None:\n",
    "    isthreshold = False\n",
    "    datethreshold = \"\"\n",
    "else:\n",
    "    isthreshold = True\n",
    "    datethreshold = pd.to_datetime(threshold,unit=\"s\")\n",
    "    \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecriture des logs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ecriture des logs\")\n",
    "\n",
    "log = {\"Date\" : GetCurrentTime(),\n",
    "       \"Seuil existant pour la suppression des anciens retweets\":isthreshold,\n",
    "       \"Date du seuil\":datethreshold,\n",
    "       \"Nombre de lignes supprimés dans la table FinalRT\":len(FinalRT) - len(KeepFinalRT),\n",
    "       \"Nombre de graph rajoutés\":compteur,\n",
    "       \"Nombre de graph enregistrés so far\":len(gdic)\n",
    "}\n",
    "\n",
    "filename = os.path.join(Root,FolderProject,\"Graph.log\")\n",
    "AppendStringToFile(filename,log)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
